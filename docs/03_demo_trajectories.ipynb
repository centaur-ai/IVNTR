{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "demo-intro",
   "metadata": {},
   "source": [
    "# Demonstration Data Generation: IVNTR's Training Data\n",
    "\n",
    "In this notebook, we'll explore how IVNTR generates training data from demonstrations using the actual implementation from `predicators/datasets/demo_only.py`. This is crucial for understanding:\n",
    "\n",
    "1. **The demonstration collection process**: Using the oracle approach through CogMan\n",
    "2. **Dataset and LowLevelTrajectory structures**: How demonstration data is organized\n",
    "3. **The actual implementation**: Real code that generates IVNTR's training data\n",
    "\n",
    "## Key Insight\n",
    "IVNTR uses the `_generate_demonstrations()` function to collect expert trajectories from the oracle approach. These demonstrations contain state-action sequences with metadata that becomes the supervised learning signal for neural predicate training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libowen/opt/anaconda3/envs/ivntr/lib/python3.8/site-packages/bosdyn/client/sdk.py:17: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n",
      "/Users/libowen/opt/anaconda3/envs/ivntr/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/Users/libowen/opt/anaconda3/envs/ivntr/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.ai')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/Users/libowen/opt/anaconda3/envs/ivntr/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete! Environment and tasks ready for demonstration generation.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add the project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Set FastDownward path\n",
    "FD_EXEC_PATH = os.path.join(os.path.dirname(os.path.abspath('.')), 'ext', 'downward')\n",
    "os.environ['FD_EXEC_PATH'] = FD_EXEC_PATH\n",
    "\n",
    "# Import IVNTR components\n",
    "from predicators.envs.satellites import SatellitesEnv\n",
    "from predicators.structs import LowLevelTrajectory, Dataset\n",
    "from predicators import utils\n",
    "from predicators.settings import CFG\n",
    "from predicators.approaches.oracle_approach import OracleApproach\n",
    "from predicators.ground_truth_models import get_gt_options\n",
    "from predicators.cogman import CogMan, run_episode_and_get_states\n",
    "from predicators.perception import create_perceiver\n",
    "from predicators.execution_monitoring import create_execution_monitor\n",
    "from predicators.datasets.demo_only import _generate_demonstrations\n",
    "\n",
    "utils.reset_config({\n",
    "    \"env\": \"satellites\",\n",
    "})\n",
    "\n",
    "# Configure for tutorial\n",
    "CFG.seed = 42\n",
    "CFG.num_train_tasks = 3\n",
    "CFG.satellites_num_sat_train = [2, 3]\n",
    "CFG.satellites_num_obj_train = [2, 3]\n",
    "CFG.timeout = 10.0\n",
    "CFG.demonstrator = \"oracle\"\n",
    "CFG.max_initial_demos = 3\n",
    "\n",
    "# Create environment\n",
    "env = SatellitesEnv(use_gui=False)\n",
    "train_tasks = env.get_train_tasks()[:3]  # Use first 3 tasks for demo\n",
    "\n",
    "print(\"‚úÖ Setup complete! Environment and tasks ready for demonstration generation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstration-process",
   "metadata": {},
   "source": [
    "## 1. The Demonstration Collection Process\n",
    "\n",
    "The `_generate_demonstrations()` function in `demo_only.py` is the core of IVNTR's data collection. Let's examine how it works:\n",
    "\n",
    "### Key Components:\n",
    "1. **Oracle Approach**: Uses ground truth NSRTs and predicates to solve tasks\n",
    "2. **CogMan (Cognitive Manager)**: Orchestrates planning and execution\n",
    "3. **Perceiver**: Processes observations into states\n",
    "4. **Execution Monitor**: Monitors option execution\n",
    "\n",
    "Let's replicate this process step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oracle-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:WARNING: you called get_or_create_env, but I couldn't find satellites in the cache. Making a new instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Setting up Oracle Approach (from demo_only.py implementation)\n",
      "\n",
      "üì¶ Ground truth options: 8\n",
      "   - ShootChemY\n",
      "   - MoveAway\n",
      "   - Calibrate\n",
      "   - ShootChemX\n",
      "   - UseCamera\n",
      "   ... (3 more)\n",
      "\n",
      "üß† Oracle Approach created with:\n",
      "   Predicates: {InfraredReadingTaken, IsCalibrated, Sees, HasInfrared, HasCamera, CameraReadingTaken, CalibrationTarget, HasChemX, ViewClear, ShootsChemX, HasChemY, ShootsChemY, GeigerReadingTaken, HasGeiger}\n",
      "   NSRTs: {NSRT-TakeGeigerReading:\n",
      "    Parameters: [?sat:satellite, ?obj:object]\n",
      "    Preconditions: [HasGeiger(?sat:satellite), IsCalibrated(?sat:satellite), Sees(?sat:satellite, ?obj:object)]\n",
      "    Add Effects: [GeigerReadingTaken(?sat:satellite, ?obj:object)]\n",
      "    Delete Effects: []\n",
      "    Ignore Effects: []\n",
      "    Option Spec: UseGeiger(?sat:satellite, ?obj:object), NSRT-TakeCameraReading:\n",
      "    Parameters: [?sat:satellite, ?obj:object]\n",
      "    Preconditions: [HasCamera(?sat:satellite), HasChemX(?obj:object), IsCalibrated(?sat:satellite), Sees(?sat:satellite, ?obj:object)]\n",
      "    Add Effects: [CameraReadingTaken(?sat:satellite, ?obj:object)]\n",
      "    Delete Effects: []\n",
      "    Ignore Effects: []\n",
      "    Option Spec: UseCamera(?sat:satellite, ?obj:object), NSRT-TakeInfraredReading:\n",
      "    Parameters: [?sat:satellite, ?obj:object]\n",
      "    Preconditions: [HasChemY(?obj:object), HasInfrared(?sat:satellite), IsCalibrated(?sat:satellite), Sees(?sat:satellite, ?obj:object)]\n",
      "    Add Effects: [InfraredReadingTaken(?sat:satellite, ?obj:object)]\n",
      "    Delete Effects: []\n",
      "    Ignore Effects: []\n",
      "    Option Spec: UseInfraRed(?sat:satellite, ?obj:object), NSRT-ShootChemY:\n",
      "    Parameters: [?sat:satellite, ?obj:object]\n",
      "    Preconditions: [Sees(?sat:satellite, ?obj:object), ShootsChemY(?sat:satellite)]\n",
      "    Add Effects: [HasChemY(?obj:object)]\n",
      "    Delete Effects: []\n",
      "    Ignore Effects: []\n",
      "    Option Spec: ShootChemY(?sat:satellite, ?obj:object), NSRT-MoveTo:\n",
      "    Parameters: [?sat:satellite, ?obj:object]\n",
      "    Preconditions: [ViewClear(?sat:satellite)]\n",
      "    Add Effects: [Sees(?sat:satellite, ?obj:object)]\n",
      "    Delete Effects: [ViewClear(?sat:satellite)]\n",
      "    Ignore Effects: []\n",
      "    Option Spec: MoveTo(?sat:satellite, ?obj:object), NSRT-MoveAway:\n",
      "    Parameters: [?sat:satellite, ?obj:object]\n",
      "    Preconditions: [Sees(?sat:satellite, ?obj:object)]\n",
      "    Add Effects: [ViewClear(?sat:satellite)]\n",
      "    Delete Effects: [Sees(?sat:satellite, ?obj:object)]\n",
      "    Ignore Effects: []\n",
      "    Option Spec: MoveAway(?sat:satellite, ?obj:object), NSRT-Calibrate:\n",
      "    Parameters: [?sat:satellite, ?obj:object]\n",
      "    Preconditions: [CalibrationTarget(?sat:satellite, ?obj:object), Sees(?sat:satellite, ?obj:object)]\n",
      "    Add Effects: [IsCalibrated(?sat:satellite)]\n",
      "    Delete Effects: []\n",
      "    Ignore Effects: []\n",
      "    Option Spec: Calibrate(?sat:satellite, ?obj:object), NSRT-ShootChemX:\n",
      "    Parameters: [?sat:satellite, ?obj:object]\n",
      "    Preconditions: [Sees(?sat:satellite, ?obj:object), ShootsChemX(?sat:satellite)]\n",
      "    Add Effects: [HasChemX(?obj:object)]\n",
      "    Delete Effects: []\n",
      "    Ignore Effects: []\n",
      "    Option Spec: ShootChemX(?sat:satellite, ?obj:object)}\n",
      "   Options: <predicators.option_model._OracleOptionModel object at 0x7fc560867970>\n",
      "\n",
      "‚öôÔ∏è CogMan created with perceiver: TrivialPerceiver\n",
      "   Execution monitor: TrivialExecutionMonitor\n",
      "\n",
      "üí° This setup exactly replicates the demo_only.py implementation!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Set up the oracle approach (as done in _generate_demonstrations)\n",
    "print(\"ü§ñ Setting up Oracle Approach (from demo_only.py implementation)\\n\")\n",
    "\n",
    "# Get ground truth options for the environment\n",
    "options = get_gt_options(env.get_name())\n",
    "print(f\"üì¶ Ground truth options: {len(options)}\")\n",
    "for opt in list(options)[:5]:  # Show first 5\n",
    "    print(f\"   - {opt.name}\")\n",
    "if len(options) > 5:\n",
    "    print(f\"   ... ({len(options)-5} more)\")\n",
    "\n",
    "# Create the oracle approach (exactly as in demo_only.py lines 152-160)\n",
    "oracle_approach = OracleApproach(\n",
    "    env.predicates,\n",
    "    options,\n",
    "    env.types,\n",
    "    env.action_space,\n",
    "    train_tasks,\n",
    "    task_planning_heuristic=CFG.offline_data_task_planning_heuristic,\n",
    "    max_skeletons_optimized=CFG.offline_data_max_skeletons_optimized,\n",
    "    bilevel_plan_without_sim=CFG.offline_data_bilevel_plan_without_sim\n",
    ")\n",
    "\n",
    "print(f\"\\nüß† Oracle Approach created with:\")\n",
    "print(f\"   Predicates: {oracle_approach._get_current_predicates()}\")\n",
    "print(f\"   NSRTs: {oracle_approach._get_current_nsrts()}\")\n",
    "print(f\"   Options: {oracle_approach.get_option_model()}\")\n",
    "\n",
    "# Create perceiver and execution monitor (as in demo_only.py lines 161-162)\n",
    "perceiver = create_perceiver(CFG.perceiver)\n",
    "execution_monitor = create_execution_monitor(CFG.execution_monitor)\n",
    "\n",
    "# Create CogMan (Cognitive Manager) - the orchestrator (line 163)\n",
    "cogman = CogMan(oracle_approach, perceiver, execution_monitor)\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è CogMan created with perceiver: {type(perceiver).__name__}\")\n",
    "print(f\"   Execution monitor: {type(execution_monitor).__name__}\")\n",
    "print(f\"\\nüí° This setup exactly replicates the demo_only.py implementation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trajectory-generation",
   "metadata": {},
   "source": [
    "## 2. Understanding Trajectory Generation\n",
    "\n",
    "Now let's see how individual trajectories are generated using the actual `run_episode_and_get_states()` function. This is the core loop from lines 189-206 in `demo_only.py`.\n",
    "\n",
    "### The Process:\n",
    "1. **Reset CogMan** for the specific task\n",
    "2. **Run episode** and collect state-action pairs\n",
    "3. **Verify goal achievement** \n",
    "4. **Create LowLevelTrajectory** with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "generate-single-trajectory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Generating Single Demonstration Trajectory\n",
      "\n",
      "üìã Task 0:\n",
      "   Goals: 2\n",
      "     - CameraReadingTaken(sat0:satellite, obj2:object)\n",
      "     - InfraredReadingTaken(sat1:satellite, obj2:object)\n",
      "\n",
      "üöÄ Running episode with oracle approach...\n",
      "‚úÖ Trajectory generated successfully!\n",
      "   Goal achieved: True\n",
      "   Length: 11 states, 10 actions\n",
      "\n",
      "üé¨ Action sequence preview:\n",
      "   Step  0: [_Option(name='MoveTo', objects=[sat1:satellite, obj2:object], params=array([0.25556993, 0.7013759 ], dtype=float32)): 0.79, 0.13, ...\n",
      "   Step  1: [_Option(name='Calibrate', objects=[sat1:satellite, obj2:object], params=array([], dtype=float32)): 0.26, 0.70, ...\n",
      "   Step  2: [_Option(name='ShootChemY', objects=[sat1:satellite, obj2:object], params=array([], dtype=float32)): 0.26, 0.70, ...\n",
      "   Step  3: [_Option(name='UseInfraRed', objects=[sat1:satellite, obj2:object], params=array([], dtype=float32)): 0.26, 0.70, ...\n",
      "   Step  4: [_Option(name='MoveTo', objects=[sat0:satellite, obj1:object], params=array([0.7858456 , 0.73400885], dtype=float32)): 0.44, 0.86, ...\n",
      "   ... (5 more actions)\n",
      "\n",
      "üìã LowLevelTrajectory created with:\n",
      "   is_demo: True\n",
      "   train_task_idx: 0\n",
      "   states: 11\n",
      "   actions: 10\n"
     ]
    }
   ],
   "source": [
    "# Generate a single trajectory (replicating demo_only.py lines 189-243)\n",
    "print(\"üéØ Generating Single Demonstration Trajectory\\n\")\n",
    "\n",
    "# Use first task\n",
    "task_idx = 0\n",
    "env_task = env.get_train_tasks()[task_idx]\n",
    "\n",
    "print(f\"üìã Task {task_idx}:\")\n",
    "print(f\"   Goals: {len(env_task.goal)}\")\n",
    "for goal in env_task.goal:\n",
    "    print(f\"     - {goal}\")\n",
    "\n",
    "# Reset CogMan for this task (line 195)\n",
    "cogman.reset(env_task)\n",
    "\n",
    "try:\n",
    "    # Generate trajectory using run_episode_and_get_states (lines 196-206)\n",
    "    print(f\"\\nüöÄ Running episode with oracle approach...\")\n",
    "    \n",
    "    traj, _, _ = run_episode_and_get_states(\n",
    "        cogman,\n",
    "        env,\n",
    "        \"train\",\n",
    "        task_idx,\n",
    "        max_num_steps=CFG.horizon,\n",
    "        exceptions_to_break_on={\n",
    "            utils.OptionExecutionFailure,\n",
    "            utils.HumanDemonstrationFailure,\n",
    "        },\n",
    "        monitor=None  # No video monitor for tutorial\n",
    "    )\n",
    "    \n",
    "    # Check goal achievement (lines 232-234)\n",
    "    goal_achieved = env_task.task.goal_holds(traj.states[-1])\n",
    "    print(f\"‚úÖ Trajectory generated successfully!\")\n",
    "    print(f\"   Goal achieved: {goal_achieved}\")\n",
    "    print(f\"   Length: {len(traj.states)} states, {len(traj.actions)} actions\")\n",
    "    \n",
    "    if goal_achieved:\n",
    "        print(f\"\\nüé¨ Action sequence preview:\")\n",
    "        for i, action in enumerate(traj.actions[:5]):  # Show first 5 actions\n",
    "            # Show action type and first few values\n",
    "            action_str = f\"[{action.get_option()}: {action.arr[0]:.2f}, {action.arr[1]:.2f}, ...\"\n",
    "            print(f\"   Step {i:2d}: {action_str}\")\n",
    "        if len(traj.actions) > 5:\n",
    "            print(f\"   ... ({len(traj.actions)-5} more actions)\")\n",
    "    \n",
    "    # Create the final LowLevelTrajectory with demo metadata (lines 240-243)\n",
    "    demo_trajectory = LowLevelTrajectory(\n",
    "        traj.states,\n",
    "        traj.actions,\n",
    "        _is_demo=True,\n",
    "        _train_task_idx=task_idx\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìã LowLevelTrajectory created with:\")\n",
    "    print(f\"   is_demo: {demo_trajectory.is_demo}\")\n",
    "    print(f\"   train_task_idx: {demo_trajectory.train_task_idx}\")\n",
    "    print(f\"   states: {len(demo_trajectory.states)}\")\n",
    "    print(f\"   actions: {len(demo_trajectory.actions)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during trajectory generation: {e}\")\n",
    "    demo_trajectory = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-structure",
   "metadata": {},
   "source": [
    "## 3. Dataset Structure and Organization\n",
    "\n",
    "Now let's examine the `Dataset` and `LowLevelTrajectory` structures that are central to IVNTR's data organization. Understanding these structures is crucial for neural predicate learning.\n",
    "\n",
    "### Key Structures:\n",
    "- **Dataset**: Collection of LowLevelTrajectory objects with optional annotations\n",
    "- **LowLevelTrajectory**: State-action sequence with demonstration metadata\n",
    "- **State**: Continuous feature vectors for all objects\n",
    "- **Action**: 10-dimensional vectors encoding control decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "analyze-structures",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analyzing Dataset and Trajectory Structures\n",
      "\n",
      "üìä Dataset Structure:\n",
      "   Type: Dataset\n",
      "   Number of trajectories: 1\n",
      "   Has annotations: False\n",
      "\n",
      "üé¨ LowLevelTrajectory Structure:\n",
      "   Type: LowLevelTrajectory\n",
      "   Is demonstration: True\n",
      "   Train task index: 0\n",
      "   States: 11 (should be actions + 1)\n",
      "   Actions: 10\n",
      "\n",
      "üèóÔ∏è State Structure Analysis:\n",
      "   Type: State\n",
      "   Objects: 2 satellites + 3 objects\n",
      "\n",
      "‚ö° Action Structure:\n",
      "   Type: Action\n",
      "   Array shape: (10,)\n",
      "   Array dtype: float32\n",
      "   Sample values: [0.7860643  0.12811363 0.1542895  0.68304896 0.25556993 0.7013759\n",
      " 0.         0.         0.         0.        ]\n",
      "   Associated option: MoveTo\n",
      "\n",
      "üí° Key Insights:\n",
      "   ‚Ä¢ States contain continuous feature dictionaries for each object\n",
      "   ‚Ä¢ Actions are 10D numpy arrays encoding control decisions\n",
      "   ‚Ä¢ Trajectories include metadata (is_demo, train_task_idx) for learning\n",
      "   ‚Ä¢ This structure provides the foundation for neural predicate learning!\n"
     ]
    }
   ],
   "source": [
    "if demo_trajectory is not None:\n",
    "    print(\"üîç Analyzing Dataset and Trajectory Structures\\n\")\n",
    "    \n",
    "    # Create a mini-dataset (as done in demo_only.py line 274)\n",
    "    mini_dataset = Dataset([demo_trajectory])\n",
    "    \n",
    "    print(f\"üìä Dataset Structure:\")\n",
    "    print(f\"   Type: {type(mini_dataset).__name__}\")\n",
    "    print(f\"   Number of trajectories: {len(mini_dataset.trajectories)}\")\n",
    "    print(f\"   Has annotations: {mini_dataset.has_annotations}\")\n",
    "    \n",
    "    # Analyze LowLevelTrajectory structure\n",
    "    traj = mini_dataset.trajectories[0]\n",
    "    print(f\"\\nüé¨ LowLevelTrajectory Structure:\")\n",
    "    print(f\"   Type: {type(traj).__name__}\")\n",
    "    print(f\"   Is demonstration: {traj.is_demo}\")\n",
    "    print(f\"   Train task index: {traj.train_task_idx}\")\n",
    "    print(f\"   States: {len(traj.states)} (should be actions + 1)\")\n",
    "    print(f\"   Actions: {len(traj.actions)}\")\n",
    "    \n",
    "    # Analyze state structure\n",
    "    init_state = traj.states[0]\n",
    "    final_state = traj.states[-1]\n",
    "    \n",
    "    print(f\"\\nüèóÔ∏è State Structure Analysis:\")\n",
    "    print(f\"   Type: {type(init_state).__name__}\")\n",
    "    \n",
    "    # Get objects from state\n",
    "    satellites = list(init_state.get_objects(env._sat_type))\n",
    "    objects = list(init_state.get_objects(env._obj_type))\n",
    "    \n",
    "    print(f\"   Objects: {len(satellites)} satellites + {len(objects)} objects\")\n",
    "    \n",
    "    # Analyze action structure\n",
    "    if traj.actions:\n",
    "        sample_action = traj.actions[0]\n",
    "        print(f\"\\n‚ö° Action Structure:\")\n",
    "        print(f\"   Type: {type(sample_action).__name__}\")\n",
    "        print(f\"   Array shape: {sample_action.arr.shape}\")\n",
    "        print(f\"   Array dtype: {sample_action.arr.dtype}\")\n",
    "        print(f\"   Sample values: {sample_action.arr}\")\n",
    "        \n",
    "        # Check if action has option information\n",
    "        if hasattr(sample_action, '_option') and sample_action._option is not None:\n",
    "            print(f\"   Associated option: {sample_action.get_option().name}\")\n",
    "        else:\n",
    "            print(f\"   Associated option: None (removed for learning)\")\n",
    "    \n",
    "    print(f\"\\nüí° Key Insights:\")\n",
    "    print(f\"   ‚Ä¢ States contain continuous feature dictionaries for each object\")\n",
    "    print(f\"   ‚Ä¢ Actions are 10D numpy arrays encoding control decisions\")\n",
    "    print(f\"   ‚Ä¢ Trajectories include metadata (is_demo, train_task_idx) for learning\")\n",
    "    print(f\"   ‚Ä¢ This structure provides the foundation for neural predicate learning!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No trajectory available for structure analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've explored IVNTR's demonstration data generation using the actual implementation:\n",
    "\n",
    "### ü§ñ **The Generation Process**\n",
    "- **Oracle Approach**: Ground truth planner with perfect domain knowledge\n",
    "- **CogMan**: Cognitive manager that orchestrates planning and execution\n",
    "- **Episode Execution**: `run_episode_and_get_states()` collects state-action trajectories\n",
    "- **Metadata Addition**: Trajectories marked as demonstrations with task indices\n",
    "\n",
    "### üìä **Data Structures**\n",
    "- **Dataset**: Collection of LowLevelTrajectory objects with optional annotations\n",
    "- **LowLevelTrajectory**: State sequences, action sequences, and demonstration metadata\n",
    "- **State**: Continuous feature dictionaries for all objects in the environment\n",
    "- **Action**: 10-dimensional numpy arrays encoding control decisions\n",
    "\n",
    "### üéØ **Key Implementation Details**\n",
    "- **Option Removal**: Oracle options removed from actions to prevent cheating (lines 247-251)\n",
    "- **Goal Verification**: Each demonstration must achieve the task goal (lines 232-234)\n",
    "- **Batch Processing**: Multiple tasks processed to create diverse training data\n",
    "- **Error Handling**: Robust handling of planning failures and timeouts\n",
    "\n",
    "### üí° **The Learning Foundation**\n",
    "This demonstration data provides the foundation for IVNTR's neural predicate learning:\n",
    "- **Supervised Signal**: Ground truth predicate labels computed from oracle knowledge\n",
    "- **State Features**: Continuous observations that neural networks must learn from\n",
    "- **Task Diversity**: Multiple scenarios ensure robust generalization\n",
    "- **Structured Format**: Consistent data organization enables systematic learning\n",
    "\n",
    "The `_generate_demonstrations()` function is the bridge between expert knowledge (oracle approach) and neural learning (predicate classifiers), providing IVNTR with the training data needed to learn symbolic abstractions from continuous observations.\n",
    "\n",
    "---\n",
    "\n",
    "**Next: `04_bilevel_learning.ipynb` - The IVNTR Learning Algorithm**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ivntr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
